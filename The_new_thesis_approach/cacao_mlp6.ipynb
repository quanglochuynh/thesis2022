{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (399,)\n",
    "batch_size = 16\n",
    "\n",
    "cwd = os.getcwd()\n",
    "x_train_dir = pathlib.Path(cwd + '/data/X_train_399.npz')\n",
    "y_train_dir = pathlib.Path(cwd + '/data/Y_train_195.npz')\n",
    "x_test_dir  = pathlib.Path(cwd + '/data/X_test_399.npz')\n",
    "y_test_dir  = pathlib.Path(cwd + '/data/Y_test_195.npz')\n",
    "checkpoint_dir = pathlib.Path('D:./TF_checkpoint/mlp/weight/')\n",
    "model_dir = pathlib.Path('D:./TF_backup/mlp/mlp7_399.h5')\n",
    "\n",
    "x_train = np.asarray(np.load(x_train_dir, allow_pickle=True)['arr_0'], dtype=np.float32)\n",
    "y_train = np.asarray(np.load(y_train_dir, allow_pickle=True)['arr_0'], dtype=np.float32)\n",
    "x_test = np.asarray(np.load(x_test_dir, allow_pickle=True)['arr_0'], dtype=np.float32)\n",
    "y_test = np.asarray(np.load(y_test_dir, allow_pickle=True)['arr_0'], dtype=np.float32)\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_dir,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6720, 399)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = layers.Normalization()\n",
    "normalizer.adapt(x_train)\n",
    "\n",
    "# Define model\n",
    "input_layer = layers.Input(shape=input_shape)\n",
    "norm = normalizer(input_layer)\n",
    "den1 = layers.Dense(512, activation='relu', kernel_initializer='HeNormal')(norm)\n",
    "drop1 = layers.Dropout(0.2)(den1)\n",
    "den2 = layers.Dense(512, activation='relu', kernel_initializer='HeNormal')(drop1)\n",
    "drop2 = layers.Dropout(0.2)(den2)\n",
    "den3 = layers.Dense(256, activation='relu', kernel_initializer='HeNormal')(drop2)\n",
    "drop3 = layers.Dropout(0.2)(den3)\n",
    "den4 = layers.Dense(14, activation='softmax')(drop3)\n",
    "model = keras.Model(input_layer, den4)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.0001,\n",
    "    momentum=0.8,\n",
    "    nesterov=True,\n",
    "    name='SGD',\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt, \n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 399)]             0         \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 399)              799       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               204800    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 14)                3598      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 603,181\n",
      "Trainable params: 602,382\n",
      "Non-trainable params: 799\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8063 - accuracy: 0.7083\n",
      "Epoch 2/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7867 - accuracy: 0.7259\n",
      "Epoch 3/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7801 - accuracy: 0.7272\n",
      "Epoch 4/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7808 - accuracy: 0.7240\n",
      "Epoch 5/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7719 - accuracy: 0.7222\n",
      "Epoch 6/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7493 - accuracy: 0.7400\n",
      "Epoch 7/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7376 - accuracy: 0.7362\n",
      "Epoch 8/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7461 - accuracy: 0.7366\n",
      "Epoch 9/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7235 - accuracy: 0.7458\n",
      "Epoch 10/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7207 - accuracy: 0.7445\n",
      "Epoch 11/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7279 - accuracy: 0.7396\n",
      "Epoch 12/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7171 - accuracy: 0.7500\n",
      "Epoch 13/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.7024 - accuracy: 0.7501\n",
      "Epoch 14/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6979 - accuracy: 0.7537\n",
      "Epoch 15/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6957 - accuracy: 0.7494\n",
      "Epoch 16/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6850 - accuracy: 0.7539\n",
      "Epoch 17/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6727 - accuracy: 0.7588\n",
      "Epoch 18/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6644 - accuracy: 0.7714\n",
      "Epoch 19/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6608 - accuracy: 0.7689\n",
      "Epoch 20/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6661 - accuracy: 0.7604\n",
      "Epoch 21/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6519 - accuracy: 0.7731\n",
      "Epoch 22/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6441 - accuracy: 0.7702\n",
      "Epoch 23/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6436 - accuracy: 0.7688\n",
      "Epoch 24/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6250 - accuracy: 0.7810\n",
      "Epoch 25/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6224 - accuracy: 0.7735\n",
      "Epoch 26/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6183 - accuracy: 0.7777\n",
      "Epoch 27/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6196 - accuracy: 0.7777\n",
      "Epoch 28/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6111 - accuracy: 0.7817\n",
      "Epoch 29/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.6143 - accuracy: 0.7746\n",
      "Epoch 30/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5931 - accuracy: 0.7865\n",
      "Epoch 31/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5978 - accuracy: 0.7881\n",
      "Epoch 32/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5774 - accuracy: 0.7888\n",
      "Epoch 33/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5911 - accuracy: 0.7940\n",
      "Epoch 34/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5878 - accuracy: 0.7888\n",
      "Epoch 35/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5709 - accuracy: 0.8003\n",
      "Epoch 36/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.7987\n",
      "Epoch 37/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5717 - accuracy: 0.7966\n",
      "Epoch 38/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5497 - accuracy: 0.8082\n",
      "Epoch 39/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5593 - accuracy: 0.8022\n",
      "Epoch 40/40\n",
      "420/420 [==============================] - 2s 4ms/step - loss: 0.5478 - accuracy: 0.8052\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=epochs, callbacks=[model_checkpoint])\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 0.7822 - accuracy: 0.7185\n",
      "Test loss: 0.7821994423866272\n",
      "Test accuracy: 0.7184523940086365\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1680, 219)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np.array([x_test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 97,  17,   0,   0,   1,   0,   0,   1,   0,   0,   0,   0,   0,\n",
      "          1],\n",
      "       [  7,  85,   0,   0,   0,   0,   0,  15,   0,   0,   0,   0,   0,\n",
      "          0],\n",
      "       [  0,   0,  86,  10,   0,   3,   2,   0,   0,   1,   0,   0,   0,\n",
      "          0],\n",
      "       [  0,   0,  17,  44,  13,   2,   0,   0,   0,  12,   5,   0,   0,\n",
      "          0],\n",
      "       [  0,   0,   3,  28,  65,   2,   0,   0,   0,   1,   8,   6,   0,\n",
      "          0],\n",
      "       [  0,   0,   0,   0,   0,  94,   0,   0,   0,   0,   0,   0,   8,\n",
      "          0],\n",
      "       [ 10,   0,   9,   0,   0,   0, 109,   0,   0,   1,   0,   0,   0,\n",
      "          2],\n",
      "       [  2,  18,   0,   0,   0,   0,   0, 102,   0,   1,   0,   0,   0,\n",
      "          1],\n",
      "       [  3,   0,   3,   0,   0,   0,   0,   0, 120,   2,   0,   0,   0,\n",
      "          0],\n",
      "       [  0,   0,   2,  11,   0,   1,   0,   2,   0,  55,   7,   0,   0,\n",
      "          0],\n",
      "       [  0,   0,   0,  17,  20,   1,   0,   0,   0,  44,  31,  17,   2,\n",
      "          0],\n",
      "       [  0,   0,   0,  10,  21,   4,   0,   0,   0,   0,  69,  97,   4,\n",
      "          0],\n",
      "       [  0,   0,   0,   0,   0,  13,   0,   0,   0,   0,   0,   0, 106,\n",
      "          0],\n",
      "       [  1,   0,   0,   0,   0,   0,   9,   0,   0,   3,   0,   0,   0,\n",
      "        116]], dtype=int16)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAF1CAYAAADFrXCQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVR0lEQVR4nO3df5TldX3f8edrZ3ZZVsCF2oIsRCAShBKjuFWUU6wuSdFQsac9LTbkgNpuf0WRY46BmtaenBPrSaxRjx7TDSK0UIxFY2gqEUqi1ARQQI6yLApBhOXXgoiLCC4z8+4f965nHGZ2Z+fe79zPeJ+Pczg7c+/d9/e9y+xzvvvde2dSVUiS2rNq1AtIkuZnoCWpUQZakhploCWpUQZakhploCWpUQZaI5PkS0n+5aj3kFploNWpJPcmeTrJD5M8kuSSJAfs44yjklSSyT085pwktyTZmWR7kt+b/fhZezyZ5Ikkf53k3yTxz4Ca5QenlsM/qqoDgJOAjcBvd3CMdcC7gBcArwI2Ab85zx4HAi8CPgD8FvDJYRx8vk8ee/qEIi2GgdayqaoHgKuBE+fel2RVkt9O8t0kO5L89yTP7999ff/HJ/pn4q+eZ/Ynqur/VdWu/nEuB05ZYI8fVNVVwD8HzknynH36O701ybb+Wfc9Sf71rPv+Qf9M/beSPAx8Ksl/TnJlksuS7ATOTfLKJDf0z9ofSvKxJGv6Mz6e5L/OOeZVSc7f8++kxoWB1rJJciTwRuDr89x9bv+/1wHHAAcAH+vfd2r/x/VVdUBV3bCIw50KbN3TA6rqq8B24O8v8JAdwBnAQcBbgT9IctKs+w8DDqF3Rr65f9uZwJXAenqfJKaB8+md2b+a3pn9v+s/9lLgLbsvsyR5AXAa8D8X8evTGDDQWg6fT/IE8BXgy8D753nMrwEfqqp7quqHwIXAWUu5TJDkbfQupXxwEQ9/kF5kn6Oq/k9V/U31fBm4hp+O+Qzwvqr6cVU93b/thqr6fFXNVNXTVXVLVd1YVVNVdS/w34DX9ud/FfgBvWgDnAV8qaoe2bdfsX5WeY1My+HNVfV/9/KYw4Hvznr/u/Q+Pg/dlwMleTPwX4DTquqxRfyUDcDjC8x6A/A+4BfoncysA7456yGPVtUzc37a/XNm/ALwIXqfMNbR+zXdMushlwJnA9f2f/zIInbWmPAMWq14kN6lgt1+DpgCHgEW9SUXk5wO/BG9fwz85iIe//foBfor89y3H/BZemfhh1bVeuALQGY9bL695t72CeBO4NiqOgj4D3NmXAacmeSXgOOBz+9tb40PA61WXAGcn+To/tPw3g/8cVVNAY/Su5xwzEI/Ocnr6V3z/Sf9SwcLSnJQkjOATwOXLRDzNcB+/WNP9c+mf2UJv64DgZ3AD5O8BPi3s++squ3A14D/AXx21qUSyUCrGRfTi9T1wHeAZ4B3AFTVj4DfBf6q/2yIk+f5+f8ReD7whf4zPX6Y5Oo5j/nfSZ6kdxnivfQuPbx1vmWq6kngncBngO8D/wK4agm/rt/s/9wn6Z3d//E8j7kU+EV6v37pJ+IX7JdGK8mp9C51vKj8A6lZPIOWRijJauA84CLjrLkMtDQiSY4HngBeCHx4pMuoSV7ikKRGeQYtSY0y0JLUqGV9JeG6g9fU+sPXdTL7qe90M3e3enruC8YkaXDP8BS76seZ775lDfT6w9fxrz792k5m33jOyzqZu9vMbXd0Or8zqya6nT8z3e38rvj7on3V0cfMTdPXLHzITo4oSRqYgZakRhloSWqUgZakRhloSWqUgZakRg0U6CSnJ/lWkruTXDCspSRJAwQ6yQTwceANwAn0vvnlCcNaTJLG3SBn0K8E7u5/k89d9L47xZnDWUuSNEigN/DT3yBze/+2n5Jkc5Kbk9z8o+/vGuBwkjReOv9HwqraUlUbq2rjuoPXdH04SfqZMUigHwCOnPX+Ef3bJElDMEigvwYc2/8uzGuAs1jaN9WUJM1jyV/NrqqmkvwG8EVgAri4qrYObTNJGnMDfbnRqvoC8IUh7SJJmsVXEkpSowy0JDXKQEtSowy0JDXKQEtSo5b1m8Y+9e3V3LTphZ3Mzv96opO5P/G6bsd3xm9eOq+J41/c6fzprd/qdL5GYAR/ljyDlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGTS7nwWpqmunHvtfN8Nd1M3a3/b58WGezp8/u7n/D1P3bO5sNsGrt2s5m1/RMZ7Ont36rs9mdWzXR7fyZ6W7na9E8g5akRhloSWqUgZakRhloSWqUgZakRhloSWqUgZakRi050EmOTPKXSe5IsjXJecNcTJLG3SCvkJgC3l1VtyY5ELglybVVdceQdpOksbbkM+iqeqiqbu2//SSwDdgwrMUkadwN5Rp0kqOAlwM3DWOeJGkIX4sjyQHAZ4F3VdXOee7fDGwGWMu6QQ8nSWNjoDPoJKvpxfnyqvrcfI+pqi1VtbGqNq5mv0EOJ0ljZZBncQT4JLCtqj40vJUkSTDYGfQpwK8Dr09yW/+/Nw5pL0kae0u+Bl1VXwEyxF0kSbP4SkJJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGDfxS73Hx7HmHdDb7oX+8vrPZh1+9prPZADP3bu9sdj27q7PZK9nkUUd2Or8ee7yz2dM7n/PVILQHnkFLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1anLUC6wYd97T2ej1G36xs9nb3v2CzmYDHPeO7Z3O13NN3Xt/p/Mn/053HzMTExOdzZ7+/vc7mz0qnkFLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1ykBLUqMMtCQ1auBAJ5lI8vUkfzaMhSRJPcM4gz4P2DaEOZKkWQYKdJIjgF8FLhrOOpKk3QY9g/4w8B5gZqEHJNmc5OYkNz/Ljwc8nCSNjyUHOskZwI6qumVPj6uqLVW1sao2rma/pR5OksbOIGfQpwBvSnIv8Gng9UkuG8pWkqSlB7qqLqyqI6rqKOAs4C+q6uyhbSZJY87nQUtSo4byBfur6kvAl4YxS5LU4xm0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSo1JVy3awg3JIvSqblu146t6Jt3T3Of72Vyz4JV6k55g87NBO5089/Egnc2+q69hZj2e++zyDlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJatTkch4sa1YzedgRncyeun97J3N3m9xweGezpx54sLPZXbv9FTOdzf5P99za2ezfOeakzmZ3btVEt/Nnprud35Gphx/pdH5Wr+lm8LNZ8C7PoCWpUQZakhploCWpUQZakhploCWpUQZakhploCWpUQZakho1UKCTrE9yZZI7k2xL8uphLSZJ427QVxJ+BPjzqvqnSdYA64awkySJAQKd5PnAqcC5AFW1C9g1nLUkSYNc4jgaeBT4VJKvJ7koyfPmPijJ5iQ3J7l51/TTAxxOksbLIIGeBE4CPlFVLweeAi6Y+6Cq2lJVG6tq45qJ/Qc4nCSNl0ECvR3YXlU39d+/kl6wJUlDsORAV9XDwP1JjuvftAm4YyhbSZIGfhbHO4DL+8/guAd46+ArSZJgwEBX1W3AxuGsIkmazVcSSlKjDLQkNcpAS1KjDLQkNcpAS1KjBn2a3T6pZ6eYfnhHJ7Pzir/bydzdpm7Z2ul8PdfvHNPd657+2baHO5sN8JnjD+t0vpZfTU93NLgWvMszaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElqlIGWpEYZaElq1ORyHixAJrr5nDBzy9ZO5u62au3azmbPPPNMZ7M1v88cf1in87/44G2dzT79Ra/sbDZAzUx3On/FGsHvi2fQktQoAy1JjTLQktQoAy1JjTLQktQoAy1JjTLQktSogQKd5PwkW5PcnuSKJN09WViSxsySA51kA/BOYGNVnQhMAGcNazFJGneDXuKYBPZPMgmsAx4cfCVJEgwQ6Kp6APggcB/wEPCDqrpmWItJ0rgb5BLHwcCZwNHA4cDzkpw9z+M2J7k5yc27+PHSN5WkMTPIJY7TgO9U1aNV9SzwOeA1cx9UVVuqamNVbVzDfgMcTpLGyyCBvg84Ocm6JAE2AduGs5YkaZBr0DcBVwK3At/sz9oypL0kaewN9PWgq+p9wPuGtIskaRZfSShJjTLQktQoAy1JjTLQktQoAy1JjTLQktSogZ5mt6+qiplnnlnOQw5NTc90NnvyqJ/rbPbUvfd1NhuAVRPdze7w29xn9ZrOZgP8w8Nf1tnse3/3FZ3NBvj5P/h2Z7OnH/teZ7N/FnkGLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNMtCS1CgDLUmNmhz1AitFPburs9kz6w/obDYnv7S72QBf3drt/I50+f+za/s/kk7n73ztizubfeDfHNrZ7Np6d2ezYTQfM55BS1KjDLQkNcpAS1KjDLQkNcpAS1KjDLQkNcpAS1Kj9hroJBcn2ZHk9lm3HZLk2iR39X88uNs1JWn8LOYM+hLg9Dm3XQBcV1XHAtf135ckDdFeA11V1wOPz7n5TODS/tuXAm8e7lqSpKW+1PvQqnqo//bDwIKv30yyGdgMsJZ1SzycJI2fgf+RsKoKqD3cv6WqNlbVxtXsN+jhJGlsLDXQjyR5IUD/xx3DW0mSBEsP9FXAOf23zwH+dDjrSJJ2W8zT7K4AbgCOS7I9yduBDwC/nOQu4LT++5KkIdrrPxJW1VsWuGvTkHeRJM3iKwklqVEGWpIaZaAlqVEGWpIaZaAlqVEGWpIatdSvxaEhWvW9nZ3Nnj7yb3U2G2Bi/7WdzZ556qnOZq9kh370rzudf9elJ3U2+5yX3dbZ7Btf0+1XPa5nd3U6fz6eQUtSowy0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSowy0JDXKQEtSowy0JDUqVbVsBzsoh9SrsmnZjqfuTRx7TGezp++6p7PZ+tnzzrvv7HT+R1/8kk7m3lTXsbMez3z3eQYtSY0y0JLUKAMtSY0y0JLUKAMtSY0y0JLUKAMtSY3aa6CTXJxkR5LbZ932+0nuTPKNJH+SZH2nW0rSGFrMGfQlwOlzbrsWOLGqXgp8G7hwyHtJ0tjba6Cr6nrg8Tm3XVNVU/13bwSO6GA3SRprw7gG/Tbg6iHMkSTNMjnIT07yXmAKuHwPj9kMbAZYy7pBDidJY2XJgU5yLnAGsKn28BWXqmoLsAV6XyxpqceTpHGzpEAnOR14D/DaqvrRcFeSJMHinmZ3BXADcFyS7UneDnwMOBC4NsltSf6w4z0laezs9Qy6qt4yz82f7GAXSdIsvpJQkhploCWpUQZakhploCWpUQZakhploCWpUQZakho10NfiWJJVE93MnZnuZq72aPquezqbPbnh8M5mTz3wYGezu7Zq7dpO588880yn87vy0Re/pNP5l9//V53M/ZU3/nDB+zyDlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJapSBlqRGGWhJalSqavkOljwKfHcffsoLgMc6WqdLK3VvWLm7r9S9wd1HoaW9X1RVf3u+O5Y10Psqyc1VtXHUe+yrlbo3rNzdV+re4O6jsFL29hKHJDXKQEtSo1oP9JZRL7BEK3VvWLm7r9S9wd1HYUXs3fQ1aEkaZ62fQUvS2Goy0ElOT/KtJHcnuWDU+yxWkiOT/GWSO5JsTXLeqHfaF0kmknw9yZ+Nepd9kWR9kiuT3JlkW5JXj3qnxUhyfv/j5PYkVyRZO+qdFpLk4iQ7ktw+67ZDklyb5K7+jwePcseFLLD77/c/Xr6R5E+SrB/higtqLtBJJoCPA28ATgDekuSE0W61aFPAu6vqBOBk4N+voN0BzgO2jXqJJfgI8OdV9RLgl1gBv4YkG4B3Ahur6kRgAjhrtFvt0SXA6XNuuwC4rqqOBa7rv9+iS3ju7tcCJ1bVS4FvAxcu91KL0VyggVcCd1fVPVW1C/g0cOaId1qUqnqoqm7tv/0kvVBsGO1Wi5PkCOBXgYtGvcu+SPJ84FTgkwBVtauqnhjpUos3CeyfZBJYBzw44n0WVFXXA4/PuflM4NL+25cCb17OnRZrvt2r6pqqmuq/eyNwxLIvtggtBnoDcP+s97ezQiI3W5KjgJcDN414lcX6MPAeYGbEe+yro4FHgU/1L89clOR5o15qb6rqAeCDwH3AQ8APquqa0W61zw6tqof6bz8MHDrKZQbwNuDqUS8xnxYDveIlOQD4LPCuqto56n32JskZwI6qumXUuyzBJHAS8ImqejnwFO3+Vfsn+tdrz6T3CeZw4HlJzh7tVktXvaeDrbinhCV5L71Lk5ePepf5tBjoB4AjZ71/RP+2FSHJanpxvryqPjfqfRbpFOBNSe6ld0np9UkuG+1Ki7Yd2F5Vu/+mciW9YLfuNOA7VfVoVT0LfA54zYh32lePJHkhQP/HHSPeZ58kORc4A/i1avT5xi0G+mvAsUmOTrKG3j+cXDXinRYlSehdC91WVR8a9T6LVVUXVtURVXUUvd/vv6iqFXE2V1UPA/cnOa5/0ybgjhGutFj3AScnWdf/uNnECvjHzTmuAs7pv30O8Kcj3GWfJDmd3iW9N1XVj0a9z0KaC3T/wv1vAF+k9wH7maraOtqtFu0U4NfpnYHe1v/vjaNeagy8A7g8yTeAlwHvH+06e9c/478SuBX4Jr0/i82+ui3JFcANwHFJtid5O/AB4JeT3EXvbwQfGOWOC1lg948BBwLX9v+c/uFIl1yArySUpEY1dwYtSeox0JLUKAMtSY0y0JLUKAMtSY0y0JLUKAMtSY0y0JLUqP8PBOnUlClcKawAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw confusion matrix\n",
    "import sys\n",
    "def progress(count, total, status=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write('[%s] %s%s ...%s\\r' % (bar, percents, '%', status))\n",
    "    sys.stdout.flush() \n",
    "\n",
    "i = 0\n",
    "cmatrix = np.zeros((14,14), dtype=np.int16)\n",
    "for i in range(len(x_test)):\n",
    "    progress(i, 1680)\n",
    "    result = model.predict(np.array([x_test[i]])).flatten()\n",
    "    id1 = np.argmax(result)\n",
    "    id2 = np.argmax(y_test[i])\n",
    "    cmatrix[id1][id2] = cmatrix[id1][id2] + 1\n",
    "    # break\n",
    "\n",
    "cmatrix = np.absolute(cmatrix)\n",
    "print(repr(cmatrix))\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(cmatrix)\n",
    "plt.title(\"Plot 2D array\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion:\n",
    "flatten vs brittle\n",
    "comp purple vs plated purple\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
