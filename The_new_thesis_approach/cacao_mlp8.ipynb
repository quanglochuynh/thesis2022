{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from image_extractor import DataSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows\n",
      "0 :  overall_geometry\n",
      "1 :  overall_rgb\n",
      "2 :  overall_hsv\n",
      "3 :  n1\n",
      "4 :  structure\n",
      "5 :  n2\n",
      "6 :  moldered\n",
      "7 :  color_grid\n",
      "8 :  color_grid_2\n",
      "9 :  glcm_grid\n",
      "10 :  comp_hsv\n",
      "11 :  glcm_2\n",
      "12 :  lbp\n",
      "x_test size: (1680, 164)\n",
      "x_train size: (6720, 164)\n",
      "y_test size: (1680, 14)\n",
      "y_train size: (6720, 14)\n",
      "Model name = ' n2_comp_hsv_n1_structure.h5 '\n",
      "D:./TF_backup/mlp/n2_comp_hsv_n1_structure.h5\n"
     ]
    }
   ],
   "source": [
    "data = DataSetup()\n",
    "data.concat(dataID=[5, 10, 3, 4])\n",
    "model_dir = 'D:./TF_backup/mlp/' + data.model_name\n",
    "checkpoint_dir = 'D:./TF_checkpoint/mlp/weight/'\n",
    "print(model_dir)\n",
    "\n",
    "\n",
    "input_shape = (data.length,)\n",
    "batch_size = 8\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_dir,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"normalization\" (type Normalization).\n\nDimensions must be equal, but are 165 and 164 for '{{node normalization/sub}} = Sub[T=DT_FLOAT](Placeholder, normalization/sub/y)' with input shapes: [?,165], [1,164].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 165), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\quang\\Documents\\thesis2022\\The_new_thesis_approach\\cacao_mlp8.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/quang/Documents/thesis2022/The_new_thesis_approach/cacao_mlp8.ipynb#ch0000002?line=3'>4</a>\u001b[0m \u001b[39m# Define model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/quang/Documents/thesis2022/The_new_thesis_approach/cacao_mlp8.ipynb#ch0000002?line=4'>5</a>\u001b[0m input_layer \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/quang/Documents/thesis2022/The_new_thesis_approach/cacao_mlp8.ipynb#ch0000002?line=5'>6</a>\u001b[0m norm \u001b[39m=\u001b[39m normalizer(input_layer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/quang/Documents/thesis2022/The_new_thesis_approach/cacao_mlp8.ipynb#ch0000002?line=6'>7</a>\u001b[0m den1 \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(\u001b[39m1024\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHeNormal\u001b[39m\u001b[39m'\u001b[39m)(norm)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/quang/Documents/thesis2022/The_new_thesis_approach/cacao_mlp8.ipynb#ch0000002?line=7'>8</a>\u001b[0m drop1 \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDropout(\u001b[39m0.2\u001b[39m)(den1)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:2013\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   2010\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   2011\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2012\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 2013\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n\u001b[0;32m   2015\u001b[0m \u001b[39mreturn\u001b[39;00m c_op\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"normalization\" (type Normalization).\n\nDimensions must be equal, but are 165 and 164 for '{{node normalization/sub}} = Sub[T=DT_FLOAT](Placeholder, normalization/sub/y)' with input shapes: [?,165], [1,164].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 165), dtype=float32)"
     ]
    }
   ],
   "source": [
    "normalizer = layers.Normalization()\n",
    "normalizer.adapt(data.x_train)\n",
    "\n",
    "# Define model\n",
    "input_layer = layers.Input(shape=input_shape)\n",
    "norm = normalizer(input_layer)\n",
    "den1 = layers.Dense(1024, activation='relu', kernel_initializer='HeNormal')(norm)\n",
    "drop1 = layers.Dropout(0.2)(den1)\n",
    "den2 = layers.Dense(1024, activation='relu', kernel_initializer='HeNormal')(drop1)\n",
    "drop2 = layers.Dropout(0.2)(den2)\n",
    "den3 = layers.Dense(1024, activation='relu', kernel_initializer='HeNormal')(drop2)\n",
    "drop3 = layers.Dropout(0.2)(den3)\n",
    "den4 = layers.Dense(14, activation='softmax')(drop3)\n",
    "model = keras.Model(input_layer, den4)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.0001,\n",
    "    momentum=0.8,\n",
    "    nesterov=True,\n",
    "    name='SGD',\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt, \n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "model.fit(data.x_train, data.y_train, batch_size=batch_size, shuffle=True, epochs=epochs, callbacks=[model_checkpoint])\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(data.x_test, data.y_test, verbose=1)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "cmatrix = np.zeros((14,14), dtype=np.int16)\n",
    "bat = int(len(data.x_test)/60)\n",
    "for i in range(0, len(data.x_test),bat):\n",
    "    result = model.predict_on_batch(data.x_test[i:i+bat])\n",
    "    ans = data.y_test[i:i+bat]\n",
    "    for j in range(bat):\n",
    "        id1 = np.argmax(result[j])\n",
    "        id2 = np.argmax(ans[j])\n",
    "        cmatrix[id1, id2] = cmatrix[id1][id2] + 1\n",
    "\n",
    "cmatrix = np.absolute(cmatrix)\n",
    "# print(repr(cmatrix))\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(cmatrix)\n",
    "plt.title(\"Plot 2D array\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(14):\n",
    "    acc.append(np.round(cmatrix[i][i]/120,3))\n",
    "print(acc)\n",
    "print(np.mean(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
